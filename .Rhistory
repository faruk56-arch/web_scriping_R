if (is.null(webpage)) {
stop("Failed to read the main page")
}
# Find all champion links
champion_links <- webpage %>%
html_nodes('a[role="button"][aria-label]') %>%
html_attr('href') %>%
unique()
# Check if any champion links were found
if (length(champion_links) == 0) {
stop("No champion links found")
}
print(champion_links)
# Extract details for each champion
champions_data <- bind_rows(lapply(champion_links, function(link) {
champion_url <- paste0('https://www.leagueoflegends.com', link)
get_champion_details(champion_url)
}))
# Clean and format the data
champions_data <- champions_data %>%
mutate(across(where(is.character), str_trim)) %>%
distinct() %>%
filter(!is.na(Name) & Name != 'NA')
# Print the cleaned data
print(champions_data)
# Save the cleaned data to a CSV file
write.csv(champions_data, 'data/cleaned_champions.csv', row.names = FALSE)
# Load required libraries
library(rvest)
library(dplyr)
library(stringr)
# Function to extract champion details from the provided URL
get_champion_details <- function(url) {
page <- tryCatch(read_html(url), error = function(e) {
print(paste("Error reading the champion page:", url, "Error:", e))
NULL
})
if (is.null(page)) {
return(data.frame(
Name = NA,
Image_URL = NA,
Description = NA,
Role = NA,
Difficulty = NA,
URL = url,
stringsAsFactors = FALSE
))
}
# Extract champion name
name_node <- page %>% html_node('div[data-testid="title"]')
name <- if (!is.null(name_node)) html_text(name_node, trim = TRUE) else 'NA'
# Extract image URL
img_node <- page %>% html_node('img[data-testid="mediaImage"]')
img <- if (!is.null(img_node)) html_attr(img_node, 'src') else 'NA'
# Extract description
description_node <- page %>% html_node('div.richText')
description <- if (!is.null(description_node)) html_text(description_node, trim = TRUE) else 'NA'
# Extract role
role_div <- page %>% html_node('div[data-testid="roles"]')
role <- if (!is.null(role_div)) html_node(role_div, 'p[data-testid="meta-details"]') %>% html_text(trim = TRUE) else 'NA'
# Extract difficulty
difficulty_div <- page %>% html_node('div[data-testid="difficulty"]')
difficulty <- if (!is.null(difficulty_div)) html_node(difficulty_div, 'p[data-testid="meta-details"]') %>% html_text(trim = TRUE) else 'NA'
data.frame(
Name = name,
Image_URL = img,
Description = description,
Role = role,
Difficulty = difficulty,
URL = url,
stringsAsFactors = FALSE
)
}
# URL of the champions page
base_url <- 'https://www.leagueoflegends.com/fr-fr/champions/'
# Get the HTML content
webpage <- tryCatch(read_html(base_url), error = function(e) {
print(paste("Error reading the main page:", e))
NULL
})
if (is.null(webpage)) {
stop("Failed to read the main page")
}
# Find all champion links
champion_links <- webpage %>%
html_nodes('a[role="button"][aria-label]') %>%
html_attr('href') %>%
unique()
# Check if any champion links were found
if (length(champion_links) == 0) {
stop("No champion links found")
}
champions_data$Description <- gsub("\\n", "", champions_data$Description)
champions_data$Description <- gsub("\\r", "", champions_data$Description)
champions_data$Description <- gsub("\\t", "", champions_data$Description)
#print(champion_links)
# Extract details for each champion
champions_data <- bind_rows(lapply(champion_links, function(link) {
champion_url <- paste0('https://www.leagueoflegends.com', link)
get_champion_details(champion_url)
}))
# Clean and format the data
champions_data <- champions_data %>%
mutate(across(where(is.character), str_trim)) %>%
distinct() %>%
filter(!is.na(Name) & Name != 'NA')
# Print the cleaned data
print(champions_data)
# Save the cleaned data to a CSV file
write.csv(champions_data, 'data/cleaned_champions.csv', row.names = FALSE)
# Load required libraries
library(rvest)
library(dplyr)
library(stringr)
# Function to extract champion details from the provided URL
get_champion_details <- function(url) {
page <- tryCatch(read_html(url), error = function(e) {
print(paste("Error reading the champion page:", url, "Error:", e))
NULL
})
if (is.null(page)) {
return(data.frame(
Name = NA,
Image_URL = NA,
Description = NA,
Role = NA,
Difficulty = NA,
URL = url,
stringsAsFactors = FALSE
))
}
# Extract champion name
name_node <- page %>% html_node('div[data-testid="title"]')
name <- if (!is.null(name_node)) html_text(name_node, trim = TRUE) else 'NA'
# Extract image URL
img_node <- page %>% html_node('img[data-testid="mediaImage"]')
img <- if (!is.null(img_node)) html_attr(img_node, 'src') else 'NA'
# Extract description
description_node <- page %>% html_node('div.richText')
description <- if (!is.null(description_node)) html_text(description_node, trim = TRUE) else 'NA'
# Extract role
role_div <- page %>% html_node('div[data-testid="roles"]')
role <- if (!is.null(role_div)) html_node(role_div, 'p[data-testid="meta-details"]') %>% html_text(trim = TRUE) else 'NA'
# Extract difficulty
difficulty_div <- page %>% html_node('div[data-testid="difficulty"]')
difficulty <- if (!is.null(difficulty_div)) html_node(difficulty_div, 'p[data-testid="meta-details"]') %>% html_text(trim = TRUE) else 'NA'
data.frame(
Name = name,
Image_URL = img,
Description = description,
Role = role,
Difficulty = difficulty,
URL = url,
stringsAsFactors = FALSE
)
}
# URL of the champions page
base_url <- 'https://www.leagueoflegends.com/fr-fr/champions/'
# Get the HTML content
webpage <- tryCatch(read_html(base_url), error = function(e) {
print(paste("Error reading the main page:", e))
NULL
})
if (is.null(webpage)) {
stop("Failed to read the main page")
}
# Find all champion links
champion_links <- webpage %>%
html_nodes('a[role="button"][aria-label]') %>%
html_attr('href') %>%
unique()
# Check if any champion links were found
if (length(champion_links) == 0) {
stop("No champion links found")
}
champions_data$Description <- gsub("\\n", "", champions_data$Description)
champions_data$Description <- gsub("\\r", "", champions_data$Description)
champions_data$Description <- gsub("\\t", "", champions_data$Description)
#print(champion_links)
# Extract details for each champion
champions_data <- bind_rows(lapply(champion_links, function(link) {
champion_url <- paste0('https://www.leagueoflegends.com', link)
get_champion_details(champion_url)
}))
# Clean and format the data
champions_data <- champions_data %>%
mutate(across(where(is.character), str_trim)) %>%
distinct() %>%
filter(!is.na(Name) & Name != 'NA')
# Print the cleaned data
print(champions_data)
# Save the cleaned data to a CSV file
write.csv(champions_data, 'data/cleanedd_champions.csv', row.names = FALSE)
print("Cleaned champion information has been saved to cleaned_champions.csv")
install.packages("shiny")
library(shiny)
# Load necessary libraries
library(shiny)
library(dplyr)
library(readr)
install.packages("readr")
library(readr)
# Load necessary libraries
library(shiny)
library(dplyr)
library(readr)
install.packages("readr")
# Load the cleaned data
file_path <- 'data/cleanedd_champions_final.csv'
champions_data <- read_csv(file_path)
library(readr)
library(ggplot2)
# Load necessary libraries
library(shiny)
library(dplyr)
library(readr)
install.packages("readr")
# Load the cleaned data
file_path <- 'data/cleanedd_champions_final.csv'
champions_data <- read_csv(file_path)
install.packages("readr")
# Load necessary libraries
library(shiny)
library(dplyr)
library(readr)
install.packages("readr")
# Load the cleaned data
file_path <- 'data/cleanedd_champions_final.csv'
champions_data <- read_csv(file_path)
library(readr)
# Load necessary libraries
library(shiny)
library(dplyr)
library(readr)
install.packages("readr")
# Load the cleaned data
file_path <- 'data/cleanedd_champions_final.csv'
champions_data <- read_csv(file_path)
# Load necessary libraries
library(shiny)
library(dplyr)
library(readr)
# Load the cleaned data
file_path <- 'data/cleanedd_champions.csv'
champions_data <- read_csv(file_path)
# Define UI for the app
ui <- fluidPage(
titlePanel("League of Legends Champions"),
sidebarLayout(
sidebarPanel(
selectInput("role", "Select Role:", choices = c("All", unique(champions_data$Role)), selected = "All"),
selectInput("difficulty", "Select Difficulty:", choices = c("All", unique(champions_data$Difficulty)), selected = "All")
),
mainPanel(
tableOutput("championTable")
)
)
)
# Define server logic for the app
server <- function(input, output) {
filtered_data <- reactive({
data <- champions_data
if (input$role != "All") {
data <- data %>% filter(Role == input$role)
}
if (input$difficulty != "All") {
data <- data %>% filter(Difficulty == input$difficulty)
}
data
})
output$championTable <- renderTable({
filtered_data()
})
}
# Run the app
shinyApp(ui = ui, server = server)
# Load necessary libraries
library(shiny)
library(dplyr)
library(readr)
library(DT)
install.packages("DT")
# Load necessary libraries
library(shiny)
library(dplyr)
library(readr)
library(DT)
# Load the cleaned data
file_path <- 'data/cleanedd_champions.csv'
champions_data <- read_csv(file_path)
# Define UI for the app
ui <- fluidPage(
titlePanel("League of Legends Champions"),
sidebarLayout(
sidebarPanel(
selectInput("role", "Select Role:", choices = c("All", unique(champions_data$Role)), selected = "All"),
selectInput("difficulty", "Select Difficulty:", choices = c("All", unique(champions_data$Difficulty)), selected = "All")
),
mainPanel(
DT::dataTableOutput("championTable")
)
)
)
# Define server logic for the app
server <- function(input, output) {
filtered_data <- reactive({
data <- champions_data
if (input$role != "All") {
data <- data %>% filter(Role == input$role)
}
if (input$difficulty != "All") {
data <- data %>% filter(Difficulty == input$difficulty)
}
data
})
output$championTable <- DT::renderDataTable({
data <- filtered_data()
data$Image_URL <- paste0('<img src="', data$Image_URL, '" width="100">')
datatable(data, escape = FALSE, options = list(autoWidth = TRUE))
})
}
# Run the app
shinyApp(ui = ui, server = server)
# Load necessary libraries
library(shiny)
library(dplyr)
library(readr)
library(DT)
# Load the cleaned data
file_path <- 'data/cleanedd_champions.csv'
champions_data <- read_csv(file_path)
# Define UI for the app
ui <- fluidPage(
titlePanel("League of Legends Champions"),
sidebarLayout(
sidebarPanel(
selectInput("role", "Select Role:", choices = c("All", unique(champions_data$Role)), selected = "All"),
selectInput("difficulty", "Select Difficulty:", choices = c("All", unique(champions_data$Difficulty)), selected = "All")
),
mainPanel(
DT::dataTableOutput("championTable")
)
)
)
# Define server logic for the app
server <- function(input, output) {
filtered_data <- reactive({
data <- champions_data
if (input$role != "All") {
data <- data %>% filter(Role == input$role)
}
if (input$difficulty != "All") {
data <- data %>% filter(Difficulty == input$difficulty)
}
data
})
output$championTable <- DT::renderDataTable({
data <- filtered_data()
data$Image_URL <- paste0('<img src="', data$Image_URL, '" width="200">')
datatable(data, escape = FALSE, options = list(autoWidth = TRUE))
})
}
# Run the app
shinyApp(ui = ui, server = server)
# Load required libraries
library(rvest)
library(dplyr)
library(stringr)
# Function to extract champion details from the provided URL
get_champion_details <- function(url) {
page <- tryCatch(read_html(url), error = function(e) {
print(paste("Error reading the champion page:", url, "Error:", e))
NULL
})
if (is.null(page)) {
return(data.frame(
Name = NA,
Image_URL = NA,
Description = NA,
Role = NA,
Difficulty = NA,
#URL = url,
stringsAsFactors = FALSE
))
}
# Extract champion name
name_node <- page %>% html_node('div[data-testid="title"]')
name <- if (!is.null(name_node)) html_text(name_node, trim = TRUE) else 'NA'
# Extract image URL
img_node <- page %>% html_node('img[data-testid="mediaImage"]')
img <- if (!is.null(img_node)) html_attr(img_node, 'src') else 'NA'
# Extract description
description_node <- page %>% html_node('div.richText')
description <- if (!is.null(description_node)) html_text(description_node, trim = TRUE) else 'NA'
# Extract role
role_div <- page %>% html_node('div[data-testid="roles"]')
role <- if (!is.null(role_div)) html_node(role_div, 'p[data-testid="meta-details"]') %>% html_text(trim = TRUE) else 'NA'
# Extract difficulty
difficulty_div <- page %>% html_node('div[data-testid="difficulty"]')
difficulty <- if (!is.null(difficulty_div)) html_node(difficulty_div, 'p[data-testid="meta-details"]') %>% html_text(trim = TRUE) else 'NA'
data.frame(
Name = name,
Image_URL = img,
Description = description,
Role = role,
Difficulty = difficulty,
#URL = url,
stringsAsFactors = FALSE
)
}
# URL of the champions page
base_url <- 'https://www.leagueoflegends.com/fr-fr/champions/'
# Get the HTML content
webpage <- tryCatch(read_html(base_url), error = function(e) {
print(paste("Error reading the main page:", e))
NULL
})
if (is.null(webpage)) {
stop("Failed to read the main page")
}
# Find all champion links
champion_links <- webpage %>%
html_nodes('a[role="button"][aria-label]') %>%
html_attr('href') %>%
unique()
# Check if any champion links were found
if (length(champion_links) == 0) {
stop("No champion links found")
}
#champions_data$Description <- gsub("\\n", "", champions_data$Description)
#champions_data$Description <- gsub("\\r", "", champions_data$Description)
#champions_data$Description <- gsub("\\t", "", champions_data$Description)
#print(champion_links)
# Extract details for each champion
champions_data <- bind_rows(lapply(champion_links, function(link) {
champion_url <- paste0('https://www.leagueoflegends.com', link)
get_champion_details(champion_url)
}))
# Load required libraries
library(rvest)
library(dplyr)
library(stringr)
# Function to extract champion details from the provided URL
get_champion_details <- function(url) {
page <- tryCatch(read_html(url), error = function(e) {
print(paste("Error reading the champion page:", url, "Error:", e))
NULL
})
if (is.null(page)) {
return(data.frame(
Name = NA,
Image_URL = NA,
Description = NA,
Role = NA,
Difficulty = NA,
#URL = url,
stringsAsFactors = FALSE
))
}
# Extract champion name
name_node <- page %>% html_node('div[data-testid="title"]')
name <- if (!is.null(name_node)) html_text(name_node, trim = TRUE) else 'NA'
# Extract image URL
img_node <- page %>% html_node('img[data-testid="mediaImage"]')
img <- if (!is.null(img_node)) html_attr(img_node, 'src') else 'NA'
# Extract description
description_node <- page %>% html_node('div.richText')
description <- if (!is.null(description_node)) html_text(description_node, trim = TRUE) else 'NA'
# Extract role
role_div <- page %>% html_node('div[data-testid="roles"]')
role <- if (!is.null(role_div)) html_node(role_div, 'p[data-testid="meta-details"]') %>% html_text(trim = TRUE) else 'NA'
# Extract difficulty
difficulty_div <- page %>% html_node('div[data-testid="difficulty"]')
difficulty <- if (!is.null(difficulty_div)) html_node(difficulty_div, 'p[data-testid="meta-details"]') %>% html_text(trim = TRUE) else 'NA'
data.frame(
Name = name,
Image_URL = img,
Description = description,
Role = role,
Difficulty = difficulty,
#URL = url,
stringsAsFactors = FALSE
)
}
# URL of the champions page
base_url <- 'https://www.leagueoflegends.com/fr-fr/champions/'
# Get the HTML content
webpage <- tryCatch(read_html(base_url), error = function(e) {
print(paste("Error reading the main page:", e))
NULL
})
if (is.null(webpage)) {
stop("Failed to read the main page")
}
# Find all champion links
champion_links <- webpage %>%
html_nodes('a[role="button"][aria-label]') %>%
html_attr('href') %>%
unique()
# Check if any champion links were found
if (length(champion_links) == 0) {
stop("No champion links found")
}
#champions_data$Description <- gsub("\\n", "", champions_data$Description)
#champions_data$Description <- gsub("\\r", "", champions_data$Description)
#champions_data$Description <- gsub("\\t", "", champions_data$Description)
#print(champion_links)
# Extract details for each champion
champions_data <- bind_rows(lapply(champion_links, function(link) {
champion_url <- paste0('https://www.leagueoflegends.com', link)
get_champion_details(champion_url)
}))
